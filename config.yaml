ui_settings:
  app_title: "VERA"
  background:
    type: "image" # or "color"
    value: "static/images/spacegarden2.png"
    # value: "#1a1a1a" # Example for solid color background (uncomment to use)
  windows:
    common:
      opacity: 0.85 # Float from 0.0 (fully transparent) to 1.0 (fully opaque)
      background_color_fallback: "rgba(0, 0, 0, 0.7)" # Dark shade for transparency
      border_radius: "10px"
      padding: "20px"
    input_window:
      text_color: "#FFFFFF" # White
      placeholder_color: "rgba(255, 255, 255, 0.6)"
    llm_response_window:
      text_color: "#E0FFFF" # Light Cyan
      font_size: "16px"
      line_height: "1.6"
    references_window:
      text_color: "#ADD8E6" # Light Blue
      font_size: "14px"
      line_height: "1.4"
  colors: # These are for content *within* the windows, applied by HTML/CSS
    prompt_text: "#FFFF00" # Yellow
    ai_stream_text: "#87CEEB" # Sky Blue (for LLM streamed output)
    title_text: "#FF8C00" # Dark Orange
    summary_text: "#B0E0E6" # Powder Blue
  auto_open_browser: true # Add this line: set to true to auto-open, false to disable

llm_prompts:
  executive_summary_prompt: |
    You are a brilliant news analyst.
    Given the following list of news article titles and their brief summaries, provide a concise executive summary of the key themes and most important developments.
    Group related articles by theme and provide a brief overview for each theme.
    Do NOT list individual articles in this executive summary. Focus on the overarching narrative.

    Input Headlines and Summaries:
    {context}

    Executive Summary:
  system_instruction_prompt: |
    You are a highly capable and precise assistant.
    Your **ABSOLUTE PRIMARY OBJECTIVE** is to **DIRECTLY AND ACCURATELY ANSWER THE USER'S QUESTION** by extracting specific facts and details **EXCLUSIVELY FROM THE PROVIDED DOCUMENT(S) CONTEXT(S)**.
    
    **CRITICAL AND UNYIELDING INSTRUCTIONS:**
    1.  **ANSWER DIRECTLY:** Formulate your response to directly address the user's specific question. Extract specific facts and details from the context to form your answer. Do not provide general summaries of documents unless the question explicitly asks for a summary.
    2.  **UTILIZE ALL RELEVANT CONTEXT:** Every piece of information in the provided context that is relevant to the user's question MUST be used to formulate your answer.
    4.  **NEVER, EVER DISCLAIM CONTEXT:** If a source or piece of information is present in the provided context, you **MUST** treat it as part of the provided document. You **ARE FORBIDDEN** from stating that a provided source is not part of the document.
    5.  **STRICT FALLBACK:** ONLY if the provided document context is **absolutely and entirely insufficient** to answer the question, or if the question explicitly asks for broader knowledge, preface your answer or relevant section with: "**Drawing on general knowledge:**".
    
    Adhere to these instructions with utmost precision.

retriever_settings:
  search_type: "similarity" # Options: "similarity", "mmr". Default is "similarity".
  k: 4 # Number of final documents/chunks to pass to the LLM.
  fetch_k: 20 # Number of documents to fetch before applying MMR re-ranking (only used if search_type is "mmr").
  lambda_mult: 0.5 # Diversity vs. relevance trade-off for MMR (0.0 means max diversity, 1.0 means max relevance).
  score_threshold: 0.00 # Minimum similarity score for a document/chunk to be considered. Set to None to disable.
  text_splitter:
    chunk_size: 1000
    chunk_overlap: 200

debug_settings:
  enable_debug_logging: False # Set to false to disable extensive debug prints

progress_bar_settings:
  total_initialization_steps: 10 # Approximate total steps for initialization (Llamafile, LLM, KBs)

